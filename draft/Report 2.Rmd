---
title: 'Report 2'
subtitle: 'Supervised learning: Classification and regression'
author: 
- Mathias Husted Torp, s133547
- Damian Kowalczyk, s166071
date: April 4th, 2017
output:
	pdf_document:
	fig_caption: yes
	number_sections: yes
	template: custom.tex
geometry: margin=1in
header-includes:
	- \renewcommand{\familydefault}{\sfdefault}
	- \usepackage{fancyhdr}
	- \usepackage{graphicx}
	- \pagestyle{fancy}
	- \fancyhead[R]{\thetitle}
	- \fancyfoot[C]{}
	- \fancyfoot[R]{\thepage}
---

```{r setup, include=FALSE}
rm(list=ls())
library(knitr)
opts_chunk$set(echo = FALSE)
opts_knit$set(root.dir = '../02450Toolbox_R')
source("../Project/load-data.R")

featuresmpg <- c('normalized-losses', 'fuel-type', 'aspiration', 'drive-wheels', 'wheel-base', 'curb-weight', 'num-of-cylinders', 'engine-size', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'price')

features_hp <- c('normalized-losses', 'wheel-base', 'length', 'width', 'bore', 'price', 'make.jaguar', 'make.mercedes-benz', 'make.porsche', 'aspiration.turbo', 'wheel-base', 'curb-weight', 'num-of-cylinders', 'engine-size',  'engine.type.dohc', 'engine.type.ohcy', 'horsepower', 'engine.location.rear','drive.wheels.rwd', 'fuel.system.mpfi')

c(dat, names, NAs) := loaddata(normalise = FALSE, removeNAs = FALSE, oneofKenc = FALSE)

```

# Classification
This part of the report will be about classifying the cars into discrete groups. Specifically, it will focus on classifying the cars into four categories of the average gas consumption per mile driven, which is a new feature based on the 'city-mpg' feature. The feature is generated based on the following rules:

- Very low = city-mpg <= Q1
- Low = Q1 < city-mpg <= median
- High = median < city-mpg <= Q3
- Very high = Q3 < city-mpg

Where Q1 means the lower quartile and Q3 means the upper quartile. The number of observations in each category is shown in Table \ref{tab:freq}.

```{r Feature definition}
y <- dat[["city-mpg"]]
dat <- dat[-which(names(dat) %in% c("city-mpg","highway-mpg"))]
class_names <- c("Very low", "Low", "High", "Very high")

yclass = factor(length(y), levels = 1:4, labels = class_names, ordered = FALSE)
yclass[y <= quantile(y,0.25)] <- class_names[1]
yclass[quantile(y,0.25) < y & y <= median(y)] <- class_names[2]
yclass[median(y) < y & y <= quantile(y,0.75)] <- class_names[3]
yclass[quantile(y,0.75) < y] <- class_names[4]

kable(t(as.matrix(table(yclass))), caption = "\\label{tab:freq}The number of observations in each of the categories of the discrete city-mpg feature.")
```

When applying the machine learning methods, neither the discrete nor the continuous version of the 'city-mpg' feature will be in the data set, just as the feature 'highway-mgp' is excluded as well. In the hope of improving the performance of the machine learning methods, a subset of features, which are intuitively believed to influence the fuel economy, was selected by hand. This subset of the data set is in the following sections compared to the full data set.

## Decision trees
```{r Decision trees, include=FALSE}
#### Format Data ####
# Data matrix
X <- dat
# Number of observations
N <- nrow(dat)
# Attribute (Feature) Names
attributeNames <- attributeNames <- gsub('-', '.', names(dat))
colnames(X) <- attributeNames
# Number of features
M <- ncol(dat)
# Vector y
y <- as.integer(yclass)
# No. of categories in vector y
C <- length(unique(yclass))
# Class names of vector y
classNames <- class_names

#### Fit tree ####
library(rpart)
library(rpart.plot)
classassignments <- classNames[y]

# construct formula to fit automatically to avoid typing in each variable name
fmla <- as.formula(paste("classassignments ~ ", paste(attributeNames, collapse= "+")))

# fit classification tree
mytree <- rpart(fmla, data=X,control=rpart.control(minsplit=20, minbucket=5, cp=0), parms=list(split='deviance'), method="class")

# Two split methods: c('gini', 'deviance)')
# Three continuous parameters: minsplit, minbucket and cp

#### Plot ####
rpart.plot(mytree, tweak = 1)

#### Predict ####
## Define a new data object with the attributes given in the text
# x = data.frame(t(c(6.9, 1.09, .06, 2.1, .0061, 12, 31, .99, 3.5, .44, 12)))
# colnames(x) <- attributeNames
## Evaluate the classification tree for the new data object
# predict(mytree, newdat=x)

```

Decision trees are an easily interpretable way of classifying data into an arbitrary number of categories. This makes them well-suited as a starting point for classifying this data set.

First, a standard decision tree
```{r Decision trees crossvalidation}

# exercise 6.1.2
#rm(list=ls())
#library(rpart)
#library(cvTools)
#source("setup.R")

#### Format Data ####
# Data matrix
X <- dat
# Number of observations
N <- nrow(dat)
# Attribute (Feature) Names
attributeNames <- attributeNames <- gsub('-', '.', names(dat))
colnames(X) <- attributeNames
# Number of features
M <- ncol(dat)
# Vector y
y <- as.integer(yclass)
# No. of categories in vector y
C <- length(unique(yclass))
# Class names of vector y
classNames <- class_names

# substitute spaces with dots to make handling of columns in data matrix easier
attributeNames <- gsub(' ', '.', attributeNames)

# Number of folds for crossvalidation
K = 10;

# Create k-fold crossvalidation partition
set.seed(1234) # for reproducibility
CV <- cvFolds(length(y), K=K)
# set up vectors that will store sizes of training and test sizes
CV$TrainSize <- c()
CV$TestSize <- c()

# Pruning levels
prune <- seq(from=0, to=0.50, length.out=20)

# Variable for classification error
Error_train = matrix(rep(NA, times=K*length(prune)), nrow=K)
Error_test = matrix(rep(NA, times=K*length(prune)), nrow=K)

for(k in 1:K){
    print(paste('Crossvalidation fold ', k, '/', K, sep=''))

    # Extract training and test set
    X_train <- X[CV$which!=k, ];
    y_train <- y[CV$which!=k];
    X_test <- X[CV$which==k, ];
    y_test <- y[CV$which==k];
    CV$TrainSize[k] <- length(y_train)
    CV$TestSize[k] <- length(y_test)

    Xdatframe_train <- data.frame(X_train)
    colnames(Xdatframe_train) <- attributeNames
    classassignments <- classNames[y_train]

    # construct formula to fit automatically to avoid typing in each variable name
    (fmla <- as.formula(paste("classassignments ~ ", paste(attributeNames, collapse= "+"))))

    # fit classification tree
    mytree <- rpart(fmla, data=Xdatframe_train,control=rpart.control(minsplit=2, minbucket=1, cp=0.01), parms=list(split='deviance'), method="class")

    Xdatframe_test <- data.frame(X_test)
    colnames(Xdatframe_test) <- attributeNames

    # Compute classification error
    for(n in 1:length(prune)){ # For each pruning level
        mytree_pruned <- prune(mytree,prune[n])
        predicted_classes_train<- classNames[predict(mytree_pruned, newdat=Xdatframe_train, type="vector")]
        predicted_classes_test<- classNames[predict(mytree_pruned, newdat=Xdatframe_test, type="vector")]
        Error_train[k,n] = sum(classNames[y_train]!= predicted_classes_train)
        Error_test[k,n] = sum(classNames[y_test]!= predicted_classes_test)
    }
}
```

```{r Decision trees plot, fig.cap='\\label{fig:tree}A non-pruned decision tree. Note that there are a lot of splits'}
rpart.plot(mytree)
```

```{r Decision trees classification error, fig.cap='\\label{fig:tree-pruning}How pruning effects the classification error. Note that for high values of pruning, the classification error stabilises around 0.75.'}

# Plot classification error
plot(c(min(prune), max(prune)), c(min(colSums(Error_train)/sum(CV$TrainSize), colSums(Error_test)/sum(CV$TestSize)), max(colSums(Error_train)/sum(CV$TrainSize), colSums(Error_test)/sum(CV$TestSize))), main='Wine decision tree: Holdout crossvalidation', xlab = 'Pruning level', ylab='Classification error', type="n")
points(prune, colSums(Error_train)/sum(CV$TrainSize), col="blue")
points(prune, colSums(Error_test)/sum(CV$TestSize), col="red");
legend('topleft', legend=c('Training error', 'Test error'), fill=c("blue", "red"));

```

```{r Decision trees pruned, fig.cap='\\label{fig:tree-pruned}How the tree looks for high pruning values. The pruning is so aggresive that only a single node remains.'}
rpart.plot(mytree_pruned)

```

## Multinomial Regression
```{r Multinomial, include=FALSE}
rm(list=ls())
source("setup.R")
source("../Project/load-data.R")
library(nnet) #install.packages("mlogit")
featuresmpg <- c('normalized-losses', 'fuel-type', 'aspiration', 'drive-wheels', 'wheel-base', 'curb-weight', 'num-of-cylinders', 'engine-size', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'price')

#### Format Data ####
# Data matrix
X <- dat
# Number of observations
N <- nrow(dat)
# Attribute (Feature) Names
attributeNames <- attributeNames <- gsub('-', '.', names(dat))
colnames(X) <- attributeNames
# Number of features
M <- ncol(dat)
# Vector y
y <- as.integer(yclass)
# No. of categories in vector y
C <- length(unique(yclass))
# Class names of vector y
classNames <- class_names

#### Perform analysis ####
X_train <- dat$X.train
N_train <- dat$N.train
y_train<- dat$y.train

X_test <- dat$X.test
N_test <- dat$N.test
y_test <- dat$y.test
# substitute spaces with dots to make handling of columns in data matrix easier
attributeNames <- gsub(' ', '.', attributeNames)
X_traindf <- data.frame(X_train)
colnames(X_traindf) <- attributeNames
X_testdf <- data.frame(X_test)
colnames(X_testdf) <- attributeNames


K = 5
# R code not working properly. The results are in the table in next section.
for(n in 1:K)

		## Classify data
		y <- dat[["city-mpg"]]
		dat <- dat[-which(names(dat) %in% c("city-mpg","highway-mpg"))]
		class_names <- c("Very low", "Low", "High", "Very high")

		yclass = factor(length(y), levels = 1:4, labels = class_names, ordered = FALSE)
		yclass[y <= quantile(y,0.25)] <- class_names[1]
		yclass[quantile(y,0.25) < y & y <= median(y)] <- class_names[2]
		yclass[median(y) < y & y <= quantile(y,0.75)] <- class_names[3]
		yclass[quantile(y,0.75) < y] <- class_names[4]

		#### Format Data ####
		# Data matrix
		X <- dat
		# Number of observations
		N <- nrow(dat)
		# Attribute (Feature) Names
		attributeNames <- attributeNames <- gsub('-', '.', names(dat))
		colnames(X) <- attributeNames
		# Number of features
		M <- ncol(dat)
		# Vector y
		y <- as.integer(yclass)
		# No. of categories in vector y
		C <- length(unique(yclass))
		# Class names of vector y
		classNames <- class_names

		# Create test and training set using cvFolds
		CV <- cvFolds(length(y), K=C)

		#### Perform analysis ####
		X_train <- X[  CV$which!=K, ]
		N_train <- sum(CV$which!=K)
		y_train <- y[  CV$which!=K ]

		X_test <- X[  CV$which==K, ]
		N_test <- sum(CV$which==K)
		y_test <- y[  CV$which==K ]
		# substitute spaces with dots to make handling of columns in data matrix easier
		attributeNames <- gsub(' ', '.', attributeNames)
		X_traindf <- data.frame(X_train)
		colnames(X_traindf) <- attributeNames
		X_testdf <- data.frame(X_test)
		colnames(X_testdf) <- attributeNames

		## Fit multinomial regression model
		Y_train=factor(y_train)
		Y_test=factor(y_test)

		(fmla <- as.formula(paste("y_train ~ ", paste(attributeNames, collapse= "+"))))
		model <- multinom(formula=fmla, data=X_traindf)
			
		## Compute results on test data
		# Get the predicted output for the test data
		Y_test_est = predict(object=model, newdata=X_testdf, type='probs')

		# Compute the class index by finding the class with highest probability from the multinomial regression model
		y_test_est <- unlist(apply(Y_test_est, 1, which.is.max))
		# Subtract one to have y_test_est between 0 and C-1
		y_test_est = y_test_est-1;

		# Compute error rate
		ErrorRate = sum(y_test!=y_test_est)/N_test;
		print(paste('Error rate: ', ErrorRate*100, '%', sep=''));
	}
}

## Plot results
# Display decision boundaries
predictionFunction <- function(Xgriddf, model){
Y_test_est <- predict(object=model, newdata=Xgriddf, type='probs')
y_test_est <- max_idx(Y_test_est);
y_test_est
}

#png("dbplot.png", 1280, 800, res = 100, type = "cairo")
#  dbplot(X_testdf, attributeNames, predictionFunction, y=y_test, contourLevels=0.5, contourCols='white', model=model)
#dev.off()
```

Multinomial regression is an expansion of logistic regression, which works with multiple categories. Since the data set in this report has been thresholded into four categories, this is the way to go.

In this report, instead of selecting parameters for the multinomial regression, parameters for the data are selected through cross-validation. This means that both normalised data and raw data are used in the model and that only some hand-chosed features are used versus all features. This makes K = 4 inner cross-validation loops.

```{r Multinomial Error rates}
kable( data.frame(All.features = "84.62 %", All.features.normalised = "86.54 %", Selected.features = "92.31 %", Selected.features.normalised = "92.31 %"), caption = "\\label{tab:multierr}The error rates when using multinomial regression to classify the cars into four classes.")
```

## K-Nearest Neighbors (KNN)
```{r K-Nearest Neighbors}

# exercise 7.1.2
rm(list=ls())
source('setup.R')
library(FNN)
library(cvTools)

# Load data
source("../Project/load-data.R")
c(dat, names, NAs) := loaddata(normalise = FALSE, removeNAs = TRUE, oneofKenc = TRUE)

# Define features
y <- dat[["city-mpg"]]
dat <- dat[-which(names(dat) %in% c("city-mpg","highway-mpg"))]
class_names <- c("Very low", "Low", "High", "Very high")

yclass = factor(length(y), levels = 1:4, labels = class_names, ordered = FALSE)
yclass[y <= quantile(y,0.25)] <- class_names[1]
yclass[quantile(y,0.25) < y & y <= median(y)] <- class_names[2]
yclass[median(y) < y & y <= quantile(y,0.75)] <- class_names[3]
yclass[quantile(y,0.75) < y] <- class_names[4]

#### Format Data ####
# Data matrix
X <- dat
# Number of observations
N <- nrow(dat)
# Attribute (Feature) Names
attributeNames <- attributeNames <- gsub('-', '.', names(dat))
colnames(X) <- attributeNames
# Number of features
M <- ncol(dat)
# Vector y
y <- as.integer(yclass)
# No. of categories in vector y
C <- length(unique(yclass))
# Class names of vector y
classNames <- class_names

# Leave-one-out crossvalidation
CV <- cvFolds(N, K=N);
K = N

# K-nearest neighbors parameters
L = 40; # Maximum number of neighbors

# Variable for classification error
Error = array(rep(NA, times=K*L), dim=c(K,L))

for(k in 1:K){ # For each crossvalidation fold
    #print(paste('Crossvalidation fold ', k, '/', CV$K, sep=''))

    # Extract training and test set
    X_train <- X[CV$which!=k, ];
    y_train <- y[CV$which!=k];
    X_test <- X[CV$which==k, ];
    y_test <- y[CV$which==k];
    CV$TrainSize[k] <- length(y_train)
    CV$TestSize[k] <- length(y_test)

	X_testdf <- data.frame(X_test)
	colnames(X_testdf) <- attributeNames
	X_traindf <- data.frame(X_train)
	colnames(X_traindf) <- attributeNames
        
    for(l in 1:L){ # For each number of neighbors
        
        # Use knnclassify to find the l nearest neighbors
        y_test_est <- knn(X_traindf, X_testdf, cl=y_train, k = l, prob = FALSE, algorithm="kd_tree")
        
        # Compute number of classification errors
        Error[k,l] = sum(y_test!=y_test_est); # Count the number of errors
    }
}

## Plot the classification error rate
plot(colSums(Error)/sum(CV$TestSize)*100, main='Classification', xlab='Number of neighbors', ylab='Classification error rate (%)', pch=20, type='l');

```

## Artificial Neural Networks (ANN)
```{r Artificial Neural Networks}

# exercise 8.3.1
rm(list=ls())
source("setup.R")
library(nnet) # install.packages('nnet')
library(doSNOW)
library(foreach)

cl<-makeCluster(3) #change the 2 to your number of CPU cores
registerDoSNOW(cl)

# Load data
source("../Project/load-data.R")
c(dat, names, NAs) := loaddata(normalise = FALSE, removeNAs = TRUE, oneofKenc = TRUE)

y <- dat[["city-mpg"]]
dat <- dat[-which(names(dat) %in% c("city-mpg","highway-mpg"))]
class_names <- c("Very low", "Low", "High", "Very high")

yclass = factor(length(y), levels = 1:4, labels = class_names, ordered = FALSE)
yclass[y <= quantile(y,0.25)] <- class_names[1]
yclass[quantile(y,0.25) < y & y <= median(y)] <- class_names[2]
yclass[median(y) < y & y <= quantile(y,0.75)] <- class_names[3]
yclass[quantile(y,0.75) < y] <- class_names[4]

#### Format Data ####
# Data matrix
X <- dat
# Number of observations
N <- nrow(dat)
# Attribute (Feature) Names
attributeNames <- attributeNames <- gsub('-', '.', names(dat))
colnames(X) <- attributeNames
# Number of features
M <- ncol(dat)
# Vector y
y <- as.integer(yclass)
# No. of categories in vector y
C <- length(unique(yclass))
# Class names of vector y
classNames <- class_names

# Extract training and test set
K = 10
CV <- cvFolds(N, K=K);

# Artificial Neural Network parameters
L = 40; # Maximum number of hidden neurons

# Variable for classification error
Error = array(rep(NA, times=K*L), dim=c(K,L))

for(k in 1:K){ # For each crossvalidation fold
    print(paste0('Crossvalidation fold ', k, '/', K))

    # Extract training and test set
	X_train <- X[CV$which!=k, ];
	y_train <- y[CV$which!=k];
	CV$TrainSize[k] <- length(y_train)

	X_test  <- X[CV$which==k, ];
	y_test  <- y[CV$which==k];
	CV$TestSize[k] <- length(y_test)

	# substitute spaces with dots to make handling of columns in data matrix easier
	attributeNames <- gsub(' ', '.', attributeNames)
	X_traindf <- data.frame(X_train)
	colnames(X_traindf) <- attributeNames
	X_testdf <- data.frame(X_test)
	colnames(X_testdf) <- attributeNames

	for(l in 20:L){ # For each number of neighbors
        print(paste0('Number of hidden neurons ', l, '/', L))
        # Parameters for neural network classifier
		NHiddenUnits = l;  # Number of hidden units
		## Fit multiclass neural network to training set
		y_trainfact <- factor(y_train)
		fmla <- as.formula(paste("y_trainfact ~ ", paste(attributeNames, collapse= "+")))
		model <- nnet(formula=fmla, data=X_traindf, size=NHiddenUnits, MaxNWts = L*72*1.05, trace=FALSE)
		    
		## Compute results on test data
		# Get the predicted output for the test data
		Y_test_est <- predict(object=model, newdata=X_testdf, type='raw')

		# Compute the class index by finding the class with highest probability from the neural
		# network
		y_test_est = max_idx(Y_test_est);

		# Compute number of classification errors
        Error[k,l] = sum(y_test!=y_test_est); # Count the number of errors
	}
}

stopCluster(cl)

## Plot the classification error rate
plot(colSums(Error)/sum(CV$TestSize)*100, main='Classification', xlab='Number of hidden neurons', ylab='Classification error rate (%)', pch=20, type='l');


## Plot results
# Display trained network
plot(model)

# Display decision boundaries
predictionFunction <- function(Xgriddf, model){
Y_test_est <- predict(object=model, newdata=Xgriddf, type='raw')
y_test_est = max_idx(Y_test_est);
y_test_est
}

dbplot(X_testdf, attributeNames, predictionFunction, y=y_test, contourLevels=0.5, contourCols='white', model=model)



```

## Prediction performance comparison
